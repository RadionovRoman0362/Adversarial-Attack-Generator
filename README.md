# Алгоритм Генерации Состязательных Атак

Этот проект является реализацией фреймворка для автоматического поиска (генерации) эффективных состязательных атак на нейронные сети для компьютерного зрения. Проект разработан в рамках Выпускной Квалификационной Работы (ВКР).

## 1. Концепция проекта

Основная идея проекта — рассматривать состязательную атаку не как монолитный алгоритм, а как **"рецепт"**, собранный из взаимозаменяемых компонентов (подобно конструктору LEGO).

Вместо того чтобы вручную создавать одну атаку, этот фреймворк предоставляет **алгоритм поиска**, который автоматически "собирает" множество различных атак из базовых "деталей", оценивает их эффективность и находит лучшую комбинацию.

**Ключевые компоненты ("детали LEGO"):**
*   **Initializer**: Как начать атаку (с нуля или со случайной точки).
*   **Loss**: Что именно "сломать" в модели (Cross-Entropy, CW-loss и т.д.).
*   **GradientComputer**: Как вычислить и модифицировать градиент (стандартный, с моментом, с аугментациями).
*   **UpdateRule**: Как применить градиент для шага атаки (по знаку, Adam, и т.д.).
*   **Scheduler**: Как изменять размер шага со временем (фиксированный, косинусный).
*   **Projector**: Как удержать атаку в заданных рамках (проекция на L-inf, L2 шар).

## 2. Архитектура

Проект построен на принципах SOLID, что делает его модульным и легко расширяемым.

*   `advgen/`: Основной пакет с библиотечным кодом.
    *   `components/`: Здесь лежат все "детали LEGO". Каждый компонент наследуется от своего абстрактного класса в `base.py`. `__init__.py` в этой папке работает как **фабрика**, которая умеет создавать любой компонент по его имени из конфига.
    *   `core/`: Ядро системы.
        *   `model_wrapper.py`: Обертка, которая стандартизирует интерфейс к любой модели (добавляет нормализацию, переводит в `eval`).
        *   `attack_runner.py`: "Сборщик", который принимает конфигурацию, создает из нее атаку с помощью фабрики и выполняет ее.
    *   `models/`: Архитектуры нейронных сетей (например, ResNet, адаптированный для CIFAR).
    *   `training/`: Логика для обучения моделей.
    *   `search/`: Логика для автоматического поиска.
        *   `samplers.py`: Генерирует случайные конфигурации атак на основе `search_space.yaml`.
        *   `evaluator.py`: Оценивает эффективность одной сгенерированной конфигурации.
    *   `utils/`: Вспомогательные утилиты (загрузчики данных, метрики, логирование).

*   `configs/`: YAML-файлы для управления всем проектом без изменения кода.
    *   `training/`: Конфиги для обучения моделей.
    *   `search_space.yaml`: **Главный файл**, описывающий все возможные "детали LEGO" и их параметры. "Грамматика" для генерации атак.
    *   `experiment_config.yaml`: Конфиг для одного конкретного запуска поиска (какую модель атаковать, сколько конфигураций проверить и т.д.).

*   `scripts/`: Исполняемые скрипты.
    *   `train.py`: Скрипт для запуска обучения модели.
    *   `run_search.py`: Главный скрипт для запуска поиска лучших атак.

*   `checkpoints/`: Здесь сохраняются обученные веса моделей (`.pth.tar`).
*   `results/`: Сюда сохраняются JSON-файлы с результатами поиска.

## 3. Инструкция по запуску и тестированию

Этот гайд описывает полный цикл работы: от настройки окружения до получения файла с лучшей найденной атакой.

### Шаг 1: Настройка окружения

1.  **Клонировать репозиторий** (если нужно) и перейти в его корневую директорию.

2.  **Создать и активировать виртуальное окружение Python 3.10+:**
    ```bash
    python3 -m venv venv
    source venv/bin/activate
    ```

3.  **Установить PyTorch с поддержкой CUDA.** Зайдите на [официальный сайт PyTorch](https://pytorch.org/get-started/locally/) и скопируйте команду для вашей версии CUDA. Например:
    ```bash
    pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
    ```

4.  **Установить остальные зависимости:**
    ```bash
    pip install -r requirements.txt
    ```

### Шаг 2: Обучение модели

Цель этого шага — получить файл с весами обученной модели (`model_best.pth.tar`), которую мы будем атаковать.

1.  **Проверить конфигурацию обучения:** Откройте файл `configs/training/train_resnet18_cifar10.yaml`. Вы можете изменить количество эпох (`epochs`), размер батча (`batch_size`) и другие параметры.

2.  **Запустить скрипт обучения:**
    ```bash
    python scripts/train.py --config configs/training/train_resnet18_cifar10.yaml
    ```
    Вы увидите прогресс-бары для каждой эпохи. Процесс займет некоторое время в зависимости от вашего GPU.

3.  **Проверить результат:** После завершения обучения в папке `checkpoints/` должны появиться два файла: `checkpoint.pth.tar` (последняя эпоха) и `model_best.pth.tar` (лучшая модель по точности на валидации). **Нам нужен `model_best.pth.tar`**.

### Шаг 3: Настройка эксперимента по поиску атак

Теперь мы настроим сам процесс поиска.

1.  **Открыть главный конфиг эксперимента:** `configs/experiment_config.yaml`.
2.  **Указать путь к модели:** Убедитесь, что параметр `checkpoint_path` в секции `model` указывает на ваш свежеобученный файл:
    ```yaml
    model:
      # ...
      checkpoint_path: "./checkpoints/model_best.pth.tar" 
    ```
3.  **Настроить параметры поиска:**
    *   `num_trials`: Сколько случайных атак сгенерировать и протестировать (например, `100`).
    *   `num_eval_samples`: На скольких картинках из тестовой выборки оценивать каждую атаку (например, `1000`). Чем больше, тем точнее, но дольше.
    *   `norm`: Для какой L-p нормы проводить поиск (`"linf"`, `"l2"`). Это важно, так как сэмплер будет генерировать компоненты, подходящие именно для этой нормы.
    *   `epsilon` и `steps`: Общие параметры силы атаки.
4.  **(Опционально) Изменить пространство поиска:** Если вы хотите добавить/убрать компоненты или изменить диапазоны их параметров, отредактируйте файл `configs/search_space.yaml`.

### Шаг 4: Запуск поиска атак

Это главный этап, где происходит автоматическая генерация и оценка.

1.  **Запустить скрипт поиска:**
    ```bash
    python scripts/run_search.py --config configs/experiment_config.yaml
    ```
2.  **Наблюдать за процессом:** В консоли вы увидите:
    *   Логи инициализации модели и данных.
    *   Сообщение о начале каждого нового "прогона" (`--- Прогон X/100 ---`).
    *   Прогресс-бар `tqdm` для оценки каждой сгенерированной атаки.
    *   Сообщение `*** Найдена новая лучшая конфигурация! ***` каждый раз, когда находится атака с более высоким `Attack Success Rate` (ASR).

### Шаг 5: Анализ результатов

После завершения всех `num_trials` скрипт закончит работу.

1.  **Найти файл с результатами:** Перейдите в папку `results/`. Там будет лежать JSON-файл с именем вроде `search_results_20240520_153000.json`.
2.  **Изучить структуру JSON:**
    *   `best_performing_attack`: Содержит полную информацию о самой успешной атаке, включая ее итоговые метрики (ASR, средние нормы) и полную конфигурацию.
    *   `all_trials`: Список, содержащий результаты **каждого** из `num_trials` прогонов. Это полезно для анализа, какие компоненты чаще встречались в успешных атаках.
    *   `experiment_config`: Копия конфигурационного файла, с которым был запущен этот поиск, для полной воспроизводимости.

**Поздравляю, вы прошли полный цикл!** Вы обучили модель, автоматически сгенерировали и протестировали сотню разных атак и получили детальный отчет о лучшей из них.